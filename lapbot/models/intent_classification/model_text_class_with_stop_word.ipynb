{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phân tích Dữ liệu Thăm dò (EDA) ---\n",
      "\n",
      "Tần suất nhãn:\n",
      " intent_tech_detail         4504\n",
      "intent_recommend_usage     3301\n",
      "intent_recommend_budget    2395\n",
      "dtype: int64\n",
      "\n",
      "--- Áp dụng tiền xử lý văn bản (Có loại bỏ Stop Words) ---\n",
      "\n",
      "--- Kích thước các tập dữ liệu ---\n",
      "Train size: 4158\n",
      "Dev size  : 1040\n",
      "Test size : 1733\n",
      "\n",
      "\n",
      "--- GridSearchCV (Thử nghiệm nhiều chiến lược) ---\n",
      "\n",
      "--- Định nghĩa bộ độ đo tập trung cho GridSearchCV ---\n",
      "Bắt đầu GridSearchCV (với dữ liệu CÓ loại bỏ stop words)...\n",
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n",
      "\n",
      "--- Kết quả GridSearchCV ---\n",
      "Chiến lược và siêu tham số tốt nhất (tối ưu theo F1-micro):\n",
      "{'clf': OneVsRestClassifier(estimator=LinearSVC(class_weight='balanced', max_iter=3000,\n",
      "                                        random_state=42),\n",
      "                    n_jobs=-1), 'clf__estimator__C': 1, 'tfidf__max_df': 0.9, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2)}\n",
      "\n",
      "Điểm F1-micro tốt nhất trên cross-validation: 0.9605\n",
      "\n",
      "\n",
      "--- Phân tích Hiệu suất các Thuật toán trên Cross-Validation ---\n",
      "\n",
      "Bảng so sánh hiệu suất tốt nhất của mỗi thuật toán/chiến lược (sắp xếp theo F1 Macro):\n",
      "Giải thích các cột:\n",
      " - F1 Macro: Hiệu suất trung bình trên các nhãn, coi mỗi nhãn quan trọng như nhau. Càng cao càng tốt.\n",
      " - Khớp Chính xác: Tỷ lệ câu hỏi được phân loại đúng hoàn toàn (nghiêm ngặt). Càng cao càng tốt.\n",
      " - Hamming Loss: Tỷ lệ nhãn bị dự đoán sai. Càng thấp càng tốt.\n",
      "--------------------------------------------------------------------------------\n",
      "                          Chiến lược  F1 Macro (CV)  Khớp Chính xác (CV)  Hamming Loss (CV)\n",
      "               LinearSVC (OneVsRest)         0.9636               0.8925             0.0386\n",
      "      LogisticRegression (OneVsRest)         0.9599               0.8836             0.0420\n",
      "LogisticRegression (ClassifierChain)         0.9586               0.8834             0.0434\n",
      "           MultinomialNB (OneVsRest)         0.9152               0.7941             0.0809\n",
      "\n",
      "\n",
      "--- Đánh giá Mô hình Tốt nhất trên Tập Dev ---\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "intent_recommend_budget       0.98      0.98      0.98       370\n",
      " intent_recommend_usage       0.96      0.95      0.95       483\n",
      "     intent_tech_detail       0.95      0.92      0.93       678\n",
      "\n",
      "              micro avg       0.96      0.94      0.95      1531\n",
      "              macro avg       0.96      0.95      0.95      1531\n",
      "           weighted avg       0.96      0.94      0.95      1531\n",
      "            samples avg       0.97      0.96      0.95      1531\n",
      "\n",
      "\n",
      "--- Tổng hợp các độ đo trên tập Dev ---\n",
      "F1-score (macro): 0.9545  (Hiệu suất trung bình trên các nhãn)\n",
      "Exact Match Ratio: 0.8635 (Tỷ lệ dự đoán đúng hoàn toàn)\n",
      "Hamming Loss: 0.0481 (Tỷ lệ nhãn bị lỗi, càng thấp càng tốt)\n",
      "\n",
      "\n",
      "--- Phân tích lỗi chi tiết và thống kê trên tập Dev ---\n",
      "\n",
      "Tổng quan: Tìm thấy 142/1040 mẫu bị lỗi (13.65%).\n",
      "\n",
      "--- Thống kê Lỗi ---\n",
      "\n",
      "Top 10 nhãn bị THÊM SAI nhiều nhất (False Positives):\n",
      "  - intent_tech_detail: 30 lần\n",
      "  - intent_recommend_usage: 20 lần\n",
      "  - intent_recommend_budget: 9 lần\n",
      "\n",
      "Top 10 nhãn bị BỎ SÓT nhiều nhất (False Negatives):\n",
      "  - intent_tech_detail: 57 lần\n",
      "  - intent_recommend_usage: 25 lần\n",
      "  - intent_recommend_budget: 9 lần\n",
      "\n",
      "\n",
      "--- Phân tích 5 ví dụ lỗi chi tiết ---\n",
      "\n",
      "----------- Lỗi #1 -----------\n",
      "Câu hỏi gốc: mẫu laptop nhẹ và nâng cấp được RAM\n",
      "Nhãn thực tế  : ['intent_recommend_usage', 'intent_tech_detail']\n",
      "Nhãn dự đoán : ['intent_tech_detail']\n",
      "Bị bỏ sót (FN)  : ['intent_recommend_usage']\n",
      "\n",
      "----------- Lỗi #2 -----------\n",
      "Câu hỏi gốc: Laptop nào có trọng lượng dưới 1.2kg cho việc di chuyển thường xuyên?\n",
      "Nhãn thực tế  : ['intent_recommend_usage', 'intent_tech_detail']\n",
      "Nhãn dự đoán : ['intent_recommend_usage']\n",
      "Bị bỏ sót (FN)  : ['intent_tech_detail']\n",
      "\n",
      "----------- Lỗi #3 -----------\n",
      "Câu hỏi gốc: Bàn phím MSI Gaming Katana 15 có tính năng đặc biệt gì, như đèn LED RGB hay phản hồi nhanh cho game thủ?\n",
      "Nhãn thực tế  : ['intent_tech_detail']\n",
      "Nhãn dự đoán : ['intent_recommend_usage', 'intent_tech_detail']\n",
      "Bị thêm sai (FP) : ['intent_recommend_usage']\n",
      "\n",
      "----------- Lỗi #4 -----------\n",
      "Câu hỏi gốc: ASUS TUF Gaming F16 FX607JU-N3139W-Xám có những thông số kỹ thuật nào về màn hình và card đồ họa?\n",
      "Nhãn thực tế  : ['intent_recommend_usage', 'intent_tech_detail']\n",
      "Nhãn dự đoán : ['intent_tech_detail']\n",
      "Bị bỏ sót (FN)  : ['intent_recommend_usage']\n",
      "\n",
      "----------- Lỗi #5 -----------\n",
      "Câu hỏi gốc: giá sinh viên là bao nhiêu?\n",
      "Nhãn thực tế  : ['intent_recommend_budget']\n",
      "Nhãn dự đoán : ['intent_recommend_budget', 'intent_recommend_usage']\n",
      "Bị thêm sai (FP) : ['intent_recommend_usage']\n",
      "\n",
      "\n",
      "--- Mô hình tốt nhất đã được lưu vào: best_intent_classifier_stopwords_removed.joblib ---\n",
      "\n",
      "\n",
      "--- Đánh giá CUỐI CÙNG của Mô hình Tốt nhất trên Tập Test ---\n",
      "\n",
      "FINAL Classification Report (Test set - Best GS Model):\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "intent_recommend_budget       0.98      0.98      0.98       593\n",
      " intent_recommend_usage       0.98      0.94      0.96       827\n",
      "     intent_tech_detail       0.95      0.94      0.94      1130\n",
      "\n",
      "              micro avg       0.96      0.95      0.96      2550\n",
      "              macro avg       0.97      0.96      0.96      2550\n",
      "           weighted avg       0.96      0.95      0.96      2550\n",
      "            samples avg       0.97      0.96      0.96      2550\n",
      "\n",
      "\n",
      "--- Tổng hợp các độ đo trên tập Test ---\n",
      "FINAL F1-score (macro): 0.9614\n",
      "FINAL Exact Match Ratio: 0.8875\n",
      "FINAL Hamming Loss: 0.0417\n",
      "\n",
      "--- HOÀN THÀNH QUY TRÌNH ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report, hamming_loss, f1_score, make_scorer, accuracy_score\n",
    "import joblib\n",
    "import re\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "\n",
    "\n",
    "\n",
    "# --- 1. Tiền xử lý với loại bỏ Stop Words ---\n",
    "VIETNAMESE_STOP_WORDS = set([\n",
    "    \"và\", \"là\", \"có\", \"được\", \"của\", \"cho\", \"thì\", \"mà\", \"ở\", \"để\", \"đã\", \"bị\", \"ra\", \"vào\",\n",
    "    \"khi\", \"thấy\", \"tại\", \"bởi\", \"vì\", \"sao\", \"nên\", \"nếu\", \"hay\", \"còn\", \"lại\", \"đến\", \"đi\", \"tới\",\n",
    "    \"luôn\", \"rất\", \"quá\", \"cũng\", \"vẫn\", \"chứ\", \"như\", \"nào\", \"gì\", \"ai\", \"đâu\", \"mấy\",\n",
    "    \"một\", \"hai\", \"ba\", \"bốn\", \"năm\", \"sáu\", \"bảy\", \"tám\", \"chín\", \"mười\",\n",
    "    \"anh\", \"em\", \"chị\", \"tôi\", \"bạn\", \"mình\",\n",
    "    \"rằng\", \"thực sự\", \"hoàn toàn\", \"chắc chắn\",\n",
    "    \"ạ\", \"nhé\", \"nha\", \"ơi\", \"đấy\", \"vậy\", \"ấy\",\n",
    "    \"lần\", \"việc\", \"cách\", \"điều\",\n",
    "    \"rồi\", \"hết\", \"ngay\", \"luôn\", \"liền\",\n",
    "    \"xin\", \"hỏi\", \"cho hỏi\", \"vui lòng\",\n",
    "    \"nó\", \"chúng\", \"họ\", \"kia\", \"đó\",\n",
    "    \"cái\", \"chiếc\", \"trong\", \"ngoài\", \"trên\", \"dưới\", \"sau\", \"trước\",\n",
    "    \"ngày\", \"tháng\"\n",
    "])\n",
    "\n",
    "def preprocess_text_with_stopwords_removal(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s\\u00C0-\\u1EF9]', ' ', text)\n",
    "    text = re.sub(r'\\d+', ' <number> ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in VIETNAMESE_STOP_WORDS and len(word) > 1]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# --- 2. Tải Dữ liệu ---\n",
    "try:\n",
    "    df_original = pd.read_csv('laptop_qa_full.csv')\n",
    "    df = df_original.copy()\n",
    "except FileNotFoundError:\n",
    "    print(\"Lỗi: File 'laptop_qa_full.csv' không tìm thấy.\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. EDA ---\n",
    "print(\"\\n--- Phân tích Dữ liệu Thăm dò (EDA) ---\")\n",
    "label_names_eda = [col for col in df.columns if col.startswith('intent_')]\n",
    "label_counts = df[label_names_eda].sum().sort_values(ascending=False)\n",
    "print(\"\\nTần suất nhãn:\\n\", label_counts)\n",
    "\n",
    "# --- 4. Tiền xử lý ---\n",
    "print(\"\\n--- Áp dụng tiền xử lý văn bản (Có loại bỏ Stop Words) ---\")\n",
    "df['processed_question'] = df['question'].astype(str).apply(preprocess_text_with_stopwords_removal)\n",
    "\n",
    "# --- 5. Tách Dữ liệu ---\n",
    "X_processed_sw = df['processed_question']\n",
    "y = df.drop(columns=['question', 'processed_question'])\n",
    "# Lấy danh sách các cột nhãn tự động\n",
    "label_names = [col for col in y.columns if 'intent_' in col]\n",
    "y = y[label_names] # Đảm bảo y chỉ chứa các cột nhãn\n",
    "y_sum_labels = y.sum(axis=1)\n",
    "stratify_param = y_sum_labels if len(np.unique(y_sum_labels)) >= 2 else None\n",
    "X_trainval_sw, X_test_sw, y_trainval, y_test = train_test_split(\n",
    "    X_processed_sw, y, test_size=0.25, random_state=42, stratify=stratify_param\n",
    ")\n",
    "y_trainval_sum_labels = y_trainval.sum(axis=1)\n",
    "stratify_trainval_param = y_trainval_sum_labels if len(np.unique(y_trainval_sum_labels)) >= 2 else None\n",
    "X_train_sw, X_dev_sw, y_train, y_dev = train_test_split(\n",
    "    X_trainval_sw, y_trainval, test_size=0.2, random_state=42, stratify=stratify_trainval_param\n",
    ")\n",
    "print(\"\\n--- Kích thước các tập dữ liệu ---\")\n",
    "print(f\"Train size: {len(X_train_sw)}\")\n",
    "print(f\"Dev size  : {len(X_dev_sw)}\")\n",
    "print(f\"Test size : {len(X_test_sw)}\")\n",
    "\n",
    "\n",
    "# --- 6. GridSearchCV để tìm siêu tham số tốt nhất ---\n",
    "print(\"\\n\\n--- GridSearchCV (Thử nghiệm nhiều chiến lược) ---\")\n",
    "pipeline_gs = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', None)\n",
    "])\n",
    "\n",
    "parameters = [\n",
    "    {'tfidf__ngram_range': [(1, 2), (1, 3)], 'tfidf__max_df': [0.9, 1.0], 'tfidf__min_df': [1, 2], 'clf': [OneVsRestClassifier(estimator=LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42), n_jobs=-1)], 'clf__estimator__C': [1, 10]},\n",
    "    {'tfidf__ngram_range': [(1, 2), (1, 3)], 'tfidf__max_df': [0.9, 1.0], 'tfidf__min_df': [1, 2], 'clf': [OneVsRestClassifier(estimator=LinearSVC(class_weight='balanced', dual='auto', random_state=42, max_iter=3000), n_jobs=-1)], 'clf__estimator__C': [0.1, 1]},\n",
    "    {'tfidf__ngram_range': [(1, 2), (1, 3)], 'tfidf__max_df': [0.9, 1.0], 'tfidf__min_df': [1, 2], 'clf': [OneVsRestClassifier(estimator=MultinomialNB(), n_jobs=-1)], 'clf__estimator__alpha': [0.1, 0.5]},\n",
    "    {'tfidf__ngram_range': [(1, 2), (1, 3)], 'tfidf__max_df': [0.9, 1.0], 'tfidf__min_df': [1, 2], 'clf': [ClassifierChain(classifier=LogisticRegression(solver='liblinear', class_weight='balanced', random_state=42), require_dense=[False, True])], 'clf__classifier__C': [1, 10]}]\n",
    "\n",
    "print(\"\\n--- Định nghĩa bộ độ đo tập trung cho GridSearchCV ---\")\n",
    "scoring = {\n",
    "    'f1_macro': make_scorer(f1_score, average='macro', zero_division=0),\n",
    "    'exact_match': make_scorer(accuracy_score),\n",
    "    'hamming': make_scorer(hamming_loss, greater_is_better=False),\n",
    "    'f1_micro': make_scorer(f1_score, average='micro', zero_division=0) # Vẫn giữ để refit\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline_gs, parameters, cv=3,\n",
    "                           scoring=scoring,\n",
    "                           refit='f1_micro',\n",
    "                           verbose=2, n_jobs=-1)\n",
    "\n",
    "\n",
    "print(\"Bắt đầu GridSearchCV (với dữ liệu CÓ loại bỏ stop words)...\")\n",
    "grid_search.fit(X_train_sw, y_train.values)\n",
    "\n",
    "print(\"\\n--- Kết quả GridSearchCV ---\")\n",
    "print(\"Chiến lược và siêu tham số tốt nhất (tối ưu theo F1-micro):\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"\\nĐiểm F1-micro tốt nhất trên cross-validation: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\n\\n--- Phân tích Hiệu suất các Thuật toán trên Cross-Validation ---\")\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "def get_classifier_strategy(param_dict):\n",
    "    clf = param_dict.get('clf')\n",
    "    if clf is not None:\n",
    "        if isinstance(clf, OneVsRestClassifier):\n",
    "            estimator_name = type(clf.estimator).__name__\n",
    "            return f\"{estimator_name} (OneVsRest)\"\n",
    "        elif isinstance(clf, ClassifierChain):\n",
    "            classifier_name = type(clf.classifier).__name__\n",
    "            return f\"{classifier_name} (ClassifierChain)\"\n",
    "    return \"Unknown\"\n",
    "results_df['strategy'] = results_df['params'].apply(get_classifier_strategy)\n",
    "best_scores_per_strategy = results_df.loc[results_df.groupby('strategy')['mean_test_f1_macro'].idxmax()]\n",
    "analysis_columns = {\n",
    "    'strategy': 'Chiến lược',\n",
    "    'mean_test_f1_macro': 'F1 Macro (CV)',\n",
    "    'mean_test_exact_match': 'Khớp Chính xác (CV)',\n",
    "    'mean_test_hamming': 'Hamming Loss (CV)'\n",
    "}\n",
    "final_analysis_df = best_scores_per_strategy[list(analysis_columns.keys())].rename(columns=analysis_columns)\n",
    "if 'Hamming Loss (CV)' in final_analysis_df.columns:\n",
    "    final_analysis_df['Hamming Loss (CV)'] = final_analysis_df['Hamming Loss (CV)'].abs()\n",
    "final_analysis_df = final_analysis_df.sort_values(by='F1 Macro (CV)', ascending=False)\n",
    "print(\"\\nBảng so sánh hiệu suất tốt nhất của mỗi thuật toán/chiến lược (sắp xếp theo F1 Macro):\")\n",
    "print(\"Giải thích các cột:\")\n",
    "print(\" - F1 Macro: Hiệu suất trung bình trên các nhãn, coi mỗi nhãn quan trọng như nhau. Càng cao càng tốt.\")\n",
    "print(\" - Khớp Chính xác: Tỷ lệ câu hỏi được phân loại đúng hoàn toàn (nghiêm ngặt). Càng cao càng tốt.\")\n",
    "print(\" - Hamming Loss: Tỷ lệ nhãn bị dự đoán sai. Càng thấp càng tốt.\")\n",
    "print(\"-\" * 80)\n",
    "print(final_analysis_df.to_string(index=False, float_format=\"%.4f\"))\n",
    "\n",
    "\n",
    "\n",
    "# --- 7. Đánh giá Mô hình Tốt nhất trên Tập Dev ---\n",
    "best_model = grid_search.best_estimator_\n",
    "y_dev_pred = best_model.predict(X_dev_sw)\n",
    "print(\"\\n\\n--- Đánh giá Mô hình Tốt nhất trên Tập Dev ---\")\n",
    "print(classification_report(y_dev, y_dev_pred, target_names=label_names, zero_division=0))\n",
    "# Báo cáo bộ độ đo đã tinh chỉnh\n",
    "print(\"\\n--- Tổng hợp các độ đo trên tập Dev ---\")\n",
    "print(f\"F1-score (macro): {f1_score(y_dev, y_dev_pred, average='macro', zero_division=0):.4f}  (Hiệu suất trung bình trên các nhãn)\")\n",
    "print(f\"Exact Match Ratio: {accuracy_score(y_dev, y_dev_pred):.4f} (Tỷ lệ dự đoán đúng hoàn toàn)\")\n",
    "print(f\"Hamming Loss: {hamming_loss(y_dev, y_dev_pred):.4f} (Tỷ lệ nhãn bị lỗi, càng thấp càng tốt)\")\n",
    "\n",
    "\n",
    "# --- 8. Phân tích lỗi  ---\n",
    "print(\"\\n\\n--- Phân tích lỗi chi tiết và thống kê trên tập Dev ---\")\n",
    "\n",
    "# Các hằng số để dễ dàng tùy chỉnh\n",
    "NUM_EXAMPLES_TO_SHOW = 5\n",
    "TOP_N_ERRORS = 10\n",
    "\n",
    "# Chuẩn bị dữ liệu để phân tích\n",
    "errors_list = []\n",
    "dev_indices = X_dev_sw.index\n",
    "y_dev_values = y_dev.values\n",
    "\n",
    "# Dùng dictionary để đếm lỗi\n",
    "fp_counts = {} # False Positives: dự đoán nhãn A nhưng thực tế không có\n",
    "fn_counts = {} # False Negatives: thực tế có nhãn A nhưng không dự đoán ra\n",
    "\n",
    "for i in range(len(X_dev_sw)):\n",
    "    actual_labels_arr = y_dev_values[i]\n",
    "    \n",
    "    # Hỗ trợ cả sparse matrix (từ ClassifierChain) và dense array\n",
    "    if hasattr(y_dev_pred, 'toarray'):\n",
    "        predicted_labels_arr = y_dev_pred[i].toarray()[0]\n",
    "    else:\n",
    "        predicted_labels_arr = y_dev_pred[i]\n",
    "        \n",
    "    # Chỉ xử lý những trường hợp có lỗi\n",
    "    if not np.array_equal(actual_labels_arr, predicted_labels_arr):\n",
    "        original_question_index = dev_indices[i]\n",
    "        \n",
    "        # Chuyển từ mảng 0/1 sang tập hợp (set) các tên nhãn để dễ so sánh\n",
    "        actual_set = {label_names[j] for j, val in enumerate(actual_labels_arr) if val == 1}\n",
    "        predicted_set = {label_names[j] for j, val in enumerate(predicted_labels_arr) if val == 1}\n",
    "        \n",
    "        # Sử dụng phép toán trên tập hợp để tìm lỗi\n",
    "        false_positives = predicted_set - actual_set\n",
    "        false_negatives = actual_set - predicted_set\n",
    "        \n",
    "        # Lưu thông tin lỗi vào danh sách\n",
    "        errors_list.append({\n",
    "            \"original_question\": df_original.loc[original_question_index, 'question'],\n",
    "            \"processed_question\": X_dev_sw.iloc[i],\n",
    "            \"actual\": actual_set if actual_set else {\"Không có\"},\n",
    "            \"predicted\": predicted_set if predicted_set else {\"Không có\"},\n",
    "            \"false_positives\": false_positives,\n",
    "            \"false_negatives\": false_negatives\n",
    "        })\n",
    "        \n",
    "        # Cập nhật bộ đếm thống kê\n",
    "        for label in false_positives:\n",
    "            fp_counts[label] = fp_counts.get(label, 0) + 1\n",
    "        for label in false_negatives:\n",
    "            fn_counts[label] = fn_counts.get(label, 0) + 1\n",
    "\n",
    "# --- Báo cáo Kết quả Phân tích Lỗi ---\n",
    "if not errors_list:\n",
    "    print(\"\\n✅ Không tìm thấy lỗi nào trên tập Dev. Mô hình hoạt động hoàn hảo!\")\n",
    "else:\n",
    "    total_errors = len(errors_list)\n",
    "    total_samples = len(X_dev_sw)\n",
    "    print(f\"\\nTổng quan: Tìm thấy {total_errors}/{total_samples} mẫu bị lỗi ({total_errors/total_samples:.2%}).\")\n",
    "\n",
    "    # 1. Thống kê các nhãn bị lỗi nhiều nhất\n",
    "    print(\"\\n--- Thống kê Lỗi ---\")\n",
    "    \n",
    "    # Sắp xếp và in ra các nhãn bị thêm sai nhiều nhất (False Positives)\n",
    "    if fp_counts:\n",
    "        sorted_fp = sorted(fp_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "        print(f\"\\nTop {TOP_N_ERRORS} nhãn bị THÊM SAI nhiều nhất (False Positives):\")\n",
    "        for label, count in sorted_fp[:TOP_N_ERRORS]:\n",
    "            print(f\"  - {label}: {count} lần\")\n",
    "            \n",
    "    # Sắp xếp và in ra các nhãn bị bỏ sót nhiều nhất (False Negatives)\n",
    "    if fn_counts:\n",
    "        sorted_fn = sorted(fn_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "        print(f\"\\nTop {TOP_N_ERRORS} nhãn bị BỎ SÓT nhiều nhất (False Negatives):\")\n",
    "        for label, count in sorted_fn[:TOP_N_ERRORS]:\n",
    "            print(f\"  - {label}: {count} lần\")\n",
    "\n",
    "    # 2. In ra ví dụ lỗi chi tiết\n",
    "    print(f\"\\n\\n--- Phân tích {min(NUM_EXAMPLES_TO_SHOW, len(errors_list))} ví dụ lỗi chi tiết ---\")\n",
    "    for i, error in enumerate(errors_list[:NUM_EXAMPLES_TO_SHOW]):\n",
    "        print(f\"\\n----------- Lỗi #{i+1} -----------\")\n",
    "        print(f\"Câu hỏi gốc: {error['original_question']}\")\n",
    "        # print(f\" Đã xử lý  : {error['processed_question']}\")\n",
    "        print(f\"Nhãn thực tế  : {sorted(list(error['actual']))}\")\n",
    "        print(f\"Nhãn dự đoán : {sorted(list(error['predicted']))}\")\n",
    "        if error['false_positives']:\n",
    "            print(f\"Bị thêm sai (FP) : {sorted(list(error['false_positives']))}\")\n",
    "        if error['false_negatives']:\n",
    "            print(f\"Bị bỏ sót (FN)  : {sorted(list(error['false_negatives']))}\")\n",
    "\n",
    "\n",
    "# --- 9. Lưu trữ Mô hình Tốt nhất ---\n",
    "model_filename = 'best_intent_classifier_stopwords_removed.joblib'\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"\\n\\n--- Mô hình tốt nhất đã được lưu vào: {model_filename} ---\")\n",
    "\n",
    "\n",
    "# --- 10. Đánh giá Cuối cùng trên Tập Test ---\n",
    "print(\"\\n\\n--- Đánh giá CUỐI CÙNG của Mô hình Tốt nhất trên Tập Test ---\")\n",
    "y_test_pred = best_model.predict(X_test_sw)\n",
    "print(\"\\nFINAL Classification Report (Test set - Best GS Model):\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=label_names, zero_division=0))\n",
    "\n",
    "print(\"\\n--- Tổng hợp các độ đo trên tập Test ---\")\n",
    "print(f\"FINAL F1-score (macro): {f1_score(y_test, y_test_pred, average='macro', zero_division=0):.4f}\")\n",
    "print(f\"FINAL Exact Match Ratio: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "print(f\"FINAL Hamming Loss: {hamming_loss(y_test, y_test_pred):.4f}\")\n",
    "\n",
    "print(\"\\n--- HOÀN THÀNH QUY TRÌNH ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
